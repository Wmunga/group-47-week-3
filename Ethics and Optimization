 Ethical Considerations (Point Form)
A. MNIST Model (Image Classification)
Bias in handwriting styles (e.g., cultural or generational variations).

 Limited representation of writing from left-handed individuals or people with disabilities.

 Risk of misclassification in critical applications (e.g., automated exam grading).

Overfitting to overly neat, standardized digits in the dataset.

B. Amazon Reviews Model (Text Classification)
 Imbalanced sentiment distribution (e.g., mostly positive reviews).

 Language and dialect bias (e.g., favors standard English over informal or regional language).

 Potential reinforcement of stereotypes from biased training data.

 Misinterpretation of sarcasm, slang, or cultural expressions.

  Bias Mitigation Tools
TensorFlow Fairness Indicators
 Measures model performance across demographic groups.

 Visualizes disparities in accuracy, precision, and false positives.

 Helps detect and address unintended biases.

spaCy Rule-Based Systems
 Creates linguistic rules to handle informal or non-standard language.

 Filters out or flags biased or offensive terms.

 Ensures more inclusive preprocessing for fairer NLP outcomes.

2. Troubleshooting challenge

Buggy Tensorflow code
import tensorflow as tf
from tensorflow.keras import layers, models

model = models.Sequential()
model.add(layers.Dense(128, input_shape=(28, 28), activation='relu'))  #  Shape mismatch
model.add(layers.Dense(10, activation='softmax'))

model.compile(optimizer='adam',
              loss='binary_crossentropy',  #  Wrong loss function
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)

Fixed Tensorflow Code
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical

#  Reshape input and normalize
x_train = x_train.reshape(-1, 28 * 28).astype('float32') / 255.0
x_test = x_test.reshape(-1, 28 * 28).astype('float32') / 255.0

#  One-hot encode the labels
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

#  Build model with correct input shape
model = models.Sequential()
model.add(layers.Dense(128, input_shape=(784,), activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

# Correct loss function for multi-class classification
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#  Fit the model
model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))

Explanation of Fixes:

Input shape changed from (28, 28) to (784,) because Dense layers expect flat inputs.

Loss function updated from binary_crossentropy to categorical_crossentropy for 10-class classification.

Labels were converted to one-hot encoded format to match expected shape for softmax output.

